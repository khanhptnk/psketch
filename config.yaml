description: Language Modeling with Memory

target:
  vc: msrlabs
  cluster: wu1

environment:
  # image: dipendramisra/pytorch_branch_fairseq:1.0
  # image: dipendramisra/fairseq:1.0
  # image: nvidia/driver:440.64.00-ubuntu18.04-aws
  # image: pytorch/pytorch:1.4-cuda10.1-cudnn7-devel
  image: kracwarlock/unlik:1.4
  #image: microsoft_pytorch:v1.2.0_gpu_cuda9.0_py36_release_gpuenv_hvd0.16.2
  #registry: phillyregistry.azurecr.io

code:
  local_dir: $CONFIG_DIR

data:
  local_dir: $CONFIG_DIR/data
  remote_dir: memory_language_data/data

search:
  job_template:
    name: search_{experiment_name:s}
    sku: G4
    command:
    - export PYTHONPATH=$PYTHONPATH:src
    - python3 -m pip install transformers==2.5.1 --user
    - python3 -m pip install tensorboardX --user
    - cd src/transformers
    - cd ../..
    - CUDA_VISIBLE_DEVICES=0,1,2,3 python3 src/experiments/train_memory_model.py --save_path $$PT_OUTPUT_DIR --cache_folder $$PT_DATA_DIR --use_memory {memory} --name memory_lang_model
  type: grid
  max_trials: 10000
  params:
    - name: memory
      spec: discrete
      values: ["True"]
